additional_parameters = ""
async_upload = false
base_weights = ""
base_weights_multiplier = ""
blocks_to_swap = 0
caching_latent_batch_size = 1
caching_latent_console_back = ""
caching_latent_console_num_images = 0
caching_latent_console_width = 80
caching_latent_device = "cuda"
caching_latent_keep_cache = false
caching_latent_num_workers = 0
caching_latent_skip_existing = true
caching_teo_batch_size = 1
caching_teo_device = "cuda"
caching_teo_fp8_llm = false
caching_teo_keep_cache = false
caching_teo_num_workers = 0
caching_teo_skip_existing = true
caching_teo_text_encoder1 = "C:\\Users\\berna\\Downloads\\llava_llama3_fp16.safetensors"
caching_teo_text_encoder2 = "C:\\Users\\berna\\Downloads\\clip_l.safetensors"
caching_teo_text_encoder_dtype = "float16"
dataset_config = "./test/config/dataset.toml"
ddp_gradient_as_bucket_view = false
ddp_static_graph = false
ddp_timeout = 0
dim_from_weights = false
discrete_flow_shift = 7
dit = "C:/Users/berna/Downloads/mp_rank_00_model_states_fp8.safetensors"
dit_dtype = "bfloat16"
dynamo_backend = "no"
dynamo_mode = "default"
dynamo_use_dynamic = false
dynamo_use_fullgraph = false
extra_accelerate_launch_args = ""
flash_attn = false
fp8_base = true
fp8_llm = false
gpu_ids = ""
gradient_accumulation_steps = 1
gradient_checkpointing = true
guidance_scale = 1
huggingface_path_in_repo = ""
huggingface_repo_id = ""
huggingface_repo_type = ""
huggingface_repo_visibility = ""
huggingface_token = ""
img_in_txt_in_offloading = false
learning_rate = 0.0002
log_config = false
log_prefix = ""
log_tracker_config = ""
log_tracker_name = ""
log_with = ""
logging_dir = ""
logit_mean = 0
logit_std = 1
lr_decay_steps = 0
lr_scheduler = "constant"
lr_scheduler_args = ""
lr_scheduler_min_lr_ratio = 0
lr_scheduler_num_cycles = 1
lr_scheduler_power = 1
lr_scheduler_timescale = 0
lr_scheduler_type = ""
lr_warmup_steps = 0
main_process_port = 0
max_data_loader_n_workers = 2
max_grad_norm = 1
max_timestep = 1000
max_train_epochs = 16
max_train_steps = 1600
metadata_author = ""
metadata_description = ""
metadata_license = ""
metadata_tags = ""
metadata_title = ""
min_timestep = 0
mixed_precision = "bf16"
mode_scale = 1.29
multi_gpu = false
network_alpha = 1
network_args = ""
network_dim = 32
network_dropout = 0
network_module = "networks.lora"
network_weights = ""
no_metadata = false
num_cpu_threads_per_process = 2
num_machines = 1
num_processes = 1
optimizer_args = ""
optimizer_type = "adamw8bit"
output_dir = "./test/output"
output_name = "name-of-lora"
persistent_data_loader_workers = true
resume = ""
resume_from_huggingface = ""
sage_attn = false
sample_at_first = false
sample_every_n_epochs = 0
sample_every_n_steps = 0
sample_prompts = ""
save_every_n_epochs = 1
save_every_n_steps = 0
save_last_n_epochs = 0
save_last_n_epochs_state = 0
save_last_n_steps = 0
save_last_n_steps_state = 0
save_state = false
save_state_on_train_end = false
save_state_to_huggingface = false
scale_weight_norms = 0
sdpa = true
seed = 42
sigmoid_scale = 1
split_attn = false
text_encoder1 = ""
text_encoder2 = ""
timestep_sampling = "shift"
training_comment = ""
vae = "C:\\Users\\berna\\Downloads\\pytorch_model.pt"
vae_chunk_size = 32
vae_dtype = "float16"
vae_spatial_tile_sample_min_size = 256
vae_tiling = true
wandb_api_key = ""
wandb_run_name = ""
weighting_scheme = "none"
xformers = false
